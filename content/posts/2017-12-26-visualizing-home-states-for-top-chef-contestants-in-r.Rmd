---
title: Visualizing home states for Top Chef contestants in R
author: Allen Chang
date: '2017-12-26'
slug: visualizing-home-states-for-top-chef-contestants-in-r
categories: []
tags: 
  - R
  - topchef
  - visualization
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Each season of Top Chef is something that I look forward to every year and it's one of the only shows that my girlfriend and I will make an hour of time for every week to watch. To my delight, this season two of my favorite writers [Tom Haberstroh](https://twitter.com/tomhaberstroh) and [Kevin Arnovitz](https://twitter.com/kevinarnovitz) have started a weekly podcast called [Pack Your Knives](https://twitter.com/PackKnives) to discuss each episode and share their love of Top Chef. During one of their first episodes, they discussed states that have never had a Top Chef contestant but moved onto other topics before finishing the list. This inspired me to try and map out the number of Top Chef contestants across US states.

First some packages. 

```{r packages, echo=TRUE, message=FALSE, warning=FALSE}
#--------------
#  PACKAGES
#--------------

library(tidyverse)
library(rvest)
library(stringr)
library(RColorBrewer)
library(reshape2)
```

### Scraping contestant information

Next I tried to scrape contestant information from Wikipedia. Early on, I had to make a choice of whether to use contestant hometowns or current locations. A scan through of the current locations for many of the chefs seemed to be suggest that many of them had not been updated (Lee Ann Wong's location has her listed in New York instead of Hawaii for example), so I opted to use hometowns. Unfortunately, the pages for seasons 1, 2, 8, 9, and 15 are missing hometown information so I ommitted them from the scrape. I might try and add the information manually later but for now my scrape included 10/15 (season 15 is airing right now) seasons.

```{r}
#--------------------------------
# Scraping contestant information
#--------------------------------

url <- "https://en.wikipedia.org/wiki/Top_Chef_(season_"
season <- c(3:7, 10:14)
bracket <- ")"
site <- paste0(url, season, bracket)

pull_table <- function(i){
  read_html(i) %>%
  html_nodes("table") %>%
    .[grepl("Name", .)] %>%
    html_table(header = FALSE, fill = TRUE) %>%
    bind_rows()
}

chef_list <- lapply(site, pull_table)
```

The contestant tables for each season are not completely identical, so I selected only the first 3 columns (Name / Hometown / Current location). Later seasons of Top Chef started a trend of bringing back previous contestants, so to avoid duplicate counts I filtered the table to only keep unique chefs. 

```{r}
#--------------------------------------------
# BIND SEASONS TOGETHER
# - keep only first 3 columns 
#   some column names differ across season
# - let's just clean them up
#--------------------------------------------

full_df <- do.call(rbind, chef_list) %>% 
  select(1:3) %>%
  filter(!X1 == "Name")

names(full_df) <- c("Chef", "Hometown","Current")
unique_chefs <- full_df %>%
  distinct()
```

Just a few more preprocessing steps. The map I used has states as lower case character strings, so I changed the state names in my scraped data to lower case. 

```{r message=FALSE, warning=FALSE}
#----------------------------------------------------------------
# LOAD MAP DATA AND CONVERT STATE NAMES TO LOWER CASE
# - store map data
#   convert character strings to lower case
#----------------------------------------------------------------
map.states <- map_data("state")

map_data('state') %>% group_by(region) %>% summarise() %>% head()

# keep only state names
unique_chefs <- unique_chefs %>%
  mutate(homestate = str_to_lower(gsub(".*, ", "", .$Hometown)), 
         currentstate = str_to_lower(gsub(".*, ", "", .$Current)))
```

I also only want to visualize only state information, so I dropped city information and finally counted the number of contestants from each state. Unfortunately that means leaving out chefs born outside of the US.

```{r}
#----------------------------------------------------------------
# RECODE DC and FILTER FOR US STATES
# - store map data
#   convert character strings to lower case
#----------------------------------------------------------------
unique_chefs$homestate <- recode(unique_chefs$homestate, "D.C" = "district of columbia")

unique_states <- unique_chefs %>%
  filter(homestate %in% map.states$region) %>%
  group_by(homestate) %>%
  summarise(count = n())
```

### Visualizing home states

Finally I have a dataframe consisting of the number of Top Chef contestants from each state. Time to plot! I of course had to use Top Chef orange to fill in each state by count. Looking at the final map, I'm not surprised to see so many contestants from California and New York. More interesting to me is the "middle" range of states including Colorado, Washington, and Michigan. This map is obviously imperfect, as I'm missing 5 seasons worth of data, but it gives a rough idea of how contestant homestates are distributed.

```{r echo=FALSE, message=FALSE, warning=FALSE}
gg <- ggplot()
gg <- gg + geom_map(data = map.states, map = map.states, 
              aes(x = long, y = lat, map_id = region),
              fill="#ffffff", color="gray", size=0.15)
gg <- gg + geom_map(data = unique_states, map = map.states,
                    aes(fill = count, map_id = homestate))
gg <- gg + scale_fill_gradientn(colours=brewer.pal(3,"Oranges"))
gg <- gg + labs(x=NULL, y=NULL, fill = "# of contestants")
# gg <- gg + coord_map("albers", lat0 = 39, lat1 = 45) 
gg <- gg + theme(panel.border = element_blank())
gg <- gg + theme(panel.background = element_blank())
gg <- gg + theme(axis.ticks = element_blank())
gg <- gg + theme(axis.text = element_blank())
gg <- gg + ggtitle("Top Chef contestant home states")
gg
```

### References
[Stack post on ggplot maps](https://stackoverflow.com/questions/29614972/ggplot-us-state-map-colors-are-fine-polygons-jagged-r)

[Sharp sight labs on web scraping](http://sharpsightlabs.com/blog/map-lithium-production-r/)